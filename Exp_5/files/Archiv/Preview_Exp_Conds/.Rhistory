#                                                            method = "LRT", args_test = list(cl =
#                                                                                               cl), #nsim=1000
#                                                            control = glmerControl(optimizer = "bobyqa",
#                                                                                   optCtrl=list(maxfun=200000)), cl = cl)
fixef(sample_model$full_model)['(Intercept)'] <- 1.04975
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up'] <- -1.02224
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible'] <- 0.52140
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:previewLinear trend'] <- 0.6
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend'] <- -0.4
VarCorr(sample_model$full_model)['id'] <- 2.426
VarCorr(sample_model$full_model)['reward'] <- 5.817
# SOURCE: osorensen, https://github.com/pitakakariki/simr/issues/39
# simulating for perturbation by preview interaction
# number of simulations 100
nsim <- 200L
# Function for repeatedly calling powerSim with nsim = 1
ps_function <- function(...) powerSim(..., nsim=1)
system.time(sim_pert_dep_preview <- future_replicate(nsim, ps_function(fit = sample_model$full_model, progress = FALSE,
test = fixed('pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend')),
simplify = F))
# set significance threshold
alpha <- 0.05
# extract pvalues
pvals <- map_dbl(sim_pert_dep_preview, ~.x$pval)
# get the confidence interval
tibble(
successes = sum(pvals < alpha),
trials = length(pvals),
mean = successes / trials
) %>%
bind_cols(as_tibble(matrix(binconf(sum(.$successes), n = length(pvals), method = "exact")[, c("Lower", "Upper")],
nrow = 1, dimnames = list(NULL, c("Lower", "upper")))))
pred.df <- reward.random.df
sample_model_pred <- reward.random.df[, c(-6)]
preds <- simulate(sample_model$full_model, 1, seed = 1234)
sample_model_pred <- cbind(sample_model_pred, preds)
colnames(sample_model_pred) <- c("reward", "pert_direct", "dependence", "preview", "id", "jump_upper")
sample_model_pred$pert_direct <- ifelse(sample_model_pred$pert_direct == 0, "Perturbation\ndownwards",
"Perturbation\nupwards")
sample_model_pred$dependence <- ifelse(sample_model_pred$dependence == 1, "Incompatible", "Compatible")
sample_model_pred$pert_direct <- as.factor(sample_model_pred$pert_direct)
contrasts(sample_model_pred$pert_direct) <- c(-0.5, 0.5)
sample_model_pred$dependence <- as.factor(sample_model_pred$pert_direct)
contrasts(sample_model_pred$dependence) <- c(-0.5, 0.5)
colnames(attr(sample_model_pred$pert_direct, "contrasts")) <-
c("Perturb down - Perturb up")
colnames(attr(sample_model_pred$dependence, "contrasts")) <-
c("Compatible - Incompatible")
sample_model <- mixed(jump_upper~pert_direct*dependence*preview + (1|id) + (1|reward), data=sample_model_pred,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
sample_model
plot_grid(
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "id") + theme_apa(),
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "reward") + theme_apa(),
labels = c("ID", "Item")
)
plan(multiprocess)
system.time(sim_pert_dep_preview <- future_replicate(nsim, ps_function(fit = sample_model$full_model, progress = FALSE,
test = fixed('pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend')),
simplify = F))
# set significance threshold
alpha <- 0.05
# extract pvalues
pvals <- map_dbl(sim_pert_dep_preview, ~.x$pval)
# get the confidence interval
tibble(
successes = sum(pvals < alpha),
trials = length(pvals),
mean = successes / trials
) %>%
bind_cols(as_tibble(matrix(binconf(sum(.$successes), n = length(pvals), method = "exact")[, c("Lower", "Upper")],
nrow = 1, dimnames = list(NULL, c("Lower", "upper")))))
pred.df <- reward.random.df
sample_model_pred <- reward.random.df[, c(-6)]
preds <- simulate(sample_model$full_model, 1, seed = 1234)
sample_model_pred <- cbind(sample_model_pred, preds)
colnames(sample_model_pred) <- c("reward", "pert_direct", "dependence", "preview", "id", "jump_upper")
sample_model_pred$pert_direct <- ifelse(sample_model_pred$pert_direct == 0, "Perturbation\ndownwards",
"Perturbation\nupwards")
sample_model_pred$dependence <- ifelse(sample_model_pred$dependence == 1, "Incompatible", "Compatible")
sample_model_pred$pert_direct <- as.factor(sample_model_pred$pert_direct)
contrasts(sample_model_pred$pert_direct) <- c(-0.5, 0.5)
sample_model_pred$dependence <- as.factor(sample_model_pred$pert_direct)
contrasts(sample_model_pred$dependence) <- c(-0.5, 0.5)
colnames(attr(sample_model_pred$pert_direct, "contrasts")) <-
c("Perturb down - Perturb up")
colnames(attr(sample_model_pred$dependence, "contrasts")) <-
c("Compatible - Incompatible")
sample_model <- mixed(jump_upper~pert_direct*dependence*preview + (1|id) + (1|reward), data=sample_model_pred,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
sample_model
plot_grid(
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "id") + theme_apa(),
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "reward") + theme_apa(),
labels = c("ID", "Item")
)
?write.csv
# practice
trial <- c(1:54, 1:54)
block <- c(rep(0, times = 108))
subblock <- c(rep(1, times = 54), rep(2, times = 54))
dependence <- c(rep(1, times = 54),  rep(-1, times = 54))
pertur_strength <- rep(1.325, times = 108)
reward_upper <- rep(0, times = 108)
reward_upper <- reward_upper + c(90, 80, 70, 60, 50, 40, 30, 20, 10)
reward_lower <- rep(0, times = 108)
reward_lower <- reward_lower + c(10, 20, 30, 40, 50, 60, 70, 80, 90)
pert_direct <- c(rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27))
training <- rep(1, times = 108)
preview <- c(rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9))
practice_conditions <- cbind(trial, block, subblock, dependence, pertur_strength, reward_upper,
reward_lower, pert_direct, training, preview)
# experimental
trial <- c(1:54, 1:54, 1:54, 1:54, 1:54, 1:54)
block <- c(rep(1, times = 162), rep(2, times = 162))
subblock <- c(rep(1, times = 54), rep(2, times = 54), rep(3, times = 54), rep(1, times = 54),
rep(2, times = 54), rep(3, times = 54))
dependence <- c(rep(1, times = 54),  rep(1, times = 54), rep(1, times = 54),  rep(-1, times = 54),
rep(-1, times = 54),  rep(-1, times = 54))
pertur_strength <- rep(1.325, times = 324)
reward_upper <- rep(0, times = 324)
reward_upper <- reward_upper + c(90, 80, 70, 60, 50, 40, 30, 20, 10)
reward_lower <- rep(0, times = 324)
reward_lower <- reward_lower + c(10, 20, 30, 40, 50, 60, 70, 80, 90)
pert_direct <- c(rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27),
rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27),
rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27))
training <- rep(0, times = 324)
preview <- c(rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9))
experimental_conditions <- cbind(trial, block, subblock, dependence, pertur_strength, reward_upper,
reward_lower, pert_direct, training, preview)
total_conditions <- rbind(practice_conditions, experimental_conditions)
total_conditions <- as.data.frame(total_conditions)
write.csv(total_conditions, file = "Exp_Conditions.csv", sep = ";", fileEncoding = "UTF-8", row.names = F)
pred.df <- reward.random.df
sample_model_pred <- reward.random.df[, c(-6)]
preds <- simulate(sample_model$full_model, 1, seed = 1234)
sample_model_pred <- cbind(sample_model_pred, preds)
colnames(sample_model_pred) <- c("reward", "pert_direct", "dependence", "preview", "id", "jump_upper")
# sample_model_pred$pert_direct <- ifelse(sample_model_pred$pert_direct == 0, "Perturbation\ndownwards",
#                                         "Perturbation\nupwards")
#
# sample_model_pred$dependence <- ifelse(sample_model_pred$dependence == 1, "Incompatible", "Compatible")
#
#
# sample_model_pred$pert_direct <- as.factor(sample_model_pred$pert_direct)
# contrasts(sample_model_pred$pert_direct) <- c(-0.5, 0.5)
#
# sample_model_pred$dependence <- as.factor(sample_model_pred$pert_direct)
#
# contrasts(sample_model_pred$dependence) <- c(-0.5, 0.5)
#
# colnames(attr(sample_model_pred$pert_direct, "contrasts")) <-
#   c("Perturb down - Perturb up")
#
# colnames(attr(sample_model_pred$dependence, "contrasts")) <-
#   c("Compatible - Incompatible")
sample_model <- mixed(jump_upper~pert_direct*dependence*preview + (1|id) + (1|reward), data=sample_model_pred,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
sample_model
plot_grid(
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "id") + theme_apa(),
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "reward") + theme_apa(),
labels = c("ID", "Item")
)
summary(reward.random.df)
summary(sample_model)
pred.df <- reward.random.df
sample_model_pred <- reward.random.df[, c(-6)]
preds <- simulate(sample_model$full_model, 1)
sample_model_pred <- cbind(sample_model_pred, preds)
colnames(sample_model_pred) <- c("reward", "pert_direct", "dependence", "preview", "id", "jump_upper")
# sample_model_pred$pert_direct <- ifelse(sample_model_pred$pert_direct == 0, "Perturbation\ndownwards",
#                                         "Perturbation\nupwards")
#
# sample_model_pred$dependence <- ifelse(sample_model_pred$dependence == 1, "Incompatible", "Compatible")
#
#
# sample_model_pred$pert_direct <- as.factor(sample_model_pred$pert_direct)
# contrasts(sample_model_pred$pert_direct) <- c(-0.5, 0.5)
#
# sample_model_pred$dependence <- as.factor(sample_model_pred$pert_direct)
#
# contrasts(sample_model_pred$dependence) <- c(-0.5, 0.5)
#
# colnames(attr(sample_model_pred$pert_direct, "contrasts")) <-
#   c("Perturb down - Perturb up")
#
# colnames(attr(sample_model_pred$dependence, "contrasts")) <-
#   c("Compatible - Incompatible")
sample_model <- mixed(jump_upper~pert_direct*dependence*preview + (1|id) + (1|reward), data=sample_model_pred,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
sample_model
plot_grid(
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "id") + theme_apa(),
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "reward") + theme_apa(),
labels = c("ID", "Item")
)
summary(sample_model)
# practice
trial <- c(1:54, 1:54)
block <- c(rep(0, times = 108))
subblock <- c(rep(1, times = 54), rep(2, times = 54))
dependence <- c(rep(1, times = 54),  rep(-1, times = 54))
pertur_strength <- rep(1.325, times = 108)
reward_upper <- rep(0, times = 108)
reward_upper <- reward_upper + c(90, 80, 70, 60, 50, 40, 30, 20, 10)
reward_lower <- rep(0, times = 108)
reward_lower <- reward_lower + c(10, 20, 30, 40, 50, 60, 70, 80, 90)
pert_direct <- c(rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27))
training <- rep(1, times = 108)
preview <- c(rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9))
practice_conditions <- cbind(trial, block, subblock, dependence, pertur_strength, reward_upper,
reward_lower, pert_direct, training, preview)
# experimental
trial <- c(1:54, 1:54, 1:54, 1:54, 1:54, 1:54)
block <- c(rep(1, times = 162), rep(2, times = 162))
subblock <- c(rep(1, times = 54), rep(2, times = 54), rep(3, times = 54), rep(1, times = 54),
rep(2, times = 54), rep(3, times = 54))
dependence <- c(rep(1, times = 54),  rep(1, times = 54), rep(1, times = 54),  rep(-1, times = 54),
rep(-1, times = 54),  rep(-1, times = 54))
pertur_strength <- rep(1.325, times = 324)
reward_upper <- rep(0, times = 324)
reward_upper <- reward_upper + c(90, 80, 70, 60, 50, 40, 30, 20, 10)
reward_lower <- rep(0, times = 324)
reward_lower <- reward_lower + c(10, 20, 30, 40, 50, 60, 70, 80, 90)
pert_direct <- c(rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27),
rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27),
rep(0, times = 27), rep(1, times = 27), rep(0, times = 27), rep(1, times = 27))
training <- rep(0, times = 324)
preview <- c(rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9),
rep("short", times = 9), rep("medium", times = 9), rep("long", times = 9))
experimental_conditions <- cbind(trial, block, subblock, dependence, pertur_strength, reward_upper,
reward_lower, pert_direct, training, preview)
total_conditions <- rbind(practice_conditions, experimental_conditions)
total_conditions <- as.data.frame(total_conditions)
write.table(total_conditions, file = "Exp_Conditions.csv", sep = ";", fileEncoding = "UTF-8", row.names = F)
9*3*2*2*6
*54
648*54
/54
34992/9
3888/2
3888/2/2
sample(1:10)
sample(1:10, 3)
34992/10
round(34992/10)
reward.random.df[(-sample(1:34992), round(34992/10))]
reward.random.df[-sample(1:34992, round(34992/10))]
reward.random.df[-sample(1:34992, round(34992/10)),]
dim(reward.random.df[-sample(1:34992, round(34992/10)),])
# 54 participants, 6 repetitions in each cell
# removing 10 percent of rows
set.seed(1234)
reward.random.df <- data_frame(
reward = rep(c(10, 20, 30, 40, 50, 60, 70, 80, 90), times = 3888),
pert_direct = rep(c(rep(0, times = 9), rep(1, times = 9)), times = 1944),
dependence = rep(c(rep(1, times = 18), rep(2, times = 18)), times = 972),
preview = rep(c(rep("short", times = 216), rep("medium", times = 216), rep("long", times = 216)), times = 50),
id = rep(1:54, each = 648),
jump_upper = rbernoulli(34992, p = 0.5)
)
reward.random.df <- reward.random.df[-sample(1:34992, round(34992/10)),]
reward.random.df$reward <- factor(reward.random.df$reward)
reward.random.df$id <- factor(reward.random.df$id)
reward.random.df$pert_direct <- factor(reward.random.df$pert_direct, levels = c(0, 1))
contrasts(reward.random.df$pert_direct) <- c(-0.5, 0.5)
reward.random.df$dependence <- factor(reward.random.df$dependence, levels = c(1, 2))
contrasts(reward.random.df$dependence) <- c(-0.5, 0.5)
reward.random.df$preview <- factor(reward.random.df$preview, levels = c("short", "medium", "long"))
contrasts(reward.random.df$preview) <- contr.poly(3)
colnames(attr(reward.random.df$pert_direct, "contrasts")) <-
c("Perturb down - Perturb up")
colnames(attr(reward.random.df$dependence, "contrasts")) <-
c("Compatible - Incompatible")
colnames(attr(reward.random.df$preview, "contrasts")) <-
c("Linear trend", "Quadratic trend")
# make clusters for multithreading
(nc <- detectCores())
cl <- makeCluster(rep("localhost", nc))
null_model <- mixed(jump_upper ~ pert_direct*dependence*preview + (1|id) + (1|reward), data=reward.random.df,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
summary(null_model)
fixed_coefs <- fixef(null_model$full_model)
fixed_coefs_length <- length(fixef(null_model$full_model))
coef_name_vector <- rep("COEF", fixed_coefs_length)
for (idx in (1:fixed_coefs_length)){
coef_name_vector[idx] <- names(fixed_coefs[idx])
}
coef_name_vector
sample_model <- null_model
fixef(sample_model$full_model)['(Intercept)'] <- 1.04975
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up'] <- -1.02224
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible'] <- 0.52140
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:previewLinear trend'] <- 0.6
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend'] <- -0.4
VarCorr(sample_model$full_model)['id'] <- 2.426
VarCorr(sample_model$full_model)['reward'] <- 5.817
# SOURCE: osorensen, https://github.com/pitakakariki/simr/issues/39
# simulating for perturbation by preview interaction
# number of simulations 100
nsim <- 200L
# Function for repeatedly calling powerSim with nsim = 1
ps_function <- function(...) powerSim(..., nsim=1)
plan(multiprocess)
system.time(sim_pert_dep_preview <- future_replicate(nsim, ps_function(fit = sample_model$full_model, progress = FALSE,
test = fixed('pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend')),
simplify = F))
# set significance threshold
alpha <- 0.05
# extract pvalues
pvals <- map_dbl(sim_pert_dep_preview, ~.x$pval)
# get the confidence interval
tibble(
successes = sum(pvals < alpha),
trials = length(pvals),
mean = successes / trials
) %>%
bind_cols(as_tibble(matrix(binconf(sum(.$successes), n = length(pvals), method = "exact")[, c("Lower", "Upper")],
nrow = 1, dimnames = list(NULL, c("Lower", "upper")))))
pred.df <- reward.random.df
sample_model_pred <- reward.random.df[, c(-6)]
preds <- simulate(sample_model$full_model, 1)
sample_model_pred <- cbind(sample_model_pred, preds)
colnames(sample_model_pred) <- c("reward", "pert_direct", "dependence", "preview", "id", "jump_upper")
# sample_model_pred$pert_direct <- ifelse(sample_model_pred$pert_direct == 0, "Perturbation\ndownwards",
#                                         "Perturbation\nupwards")
#
# sample_model_pred$dependence <- ifelse(sample_model_pred$dependence == 1, "Incompatible", "Compatible")
#
#
# sample_model_pred$pert_direct <- as.factor(sample_model_pred$pert_direct)
# contrasts(sample_model_pred$pert_direct) <- c(-0.5, 0.5)
#
# sample_model_pred$dependence <- as.factor(sample_model_pred$pert_direct)
#
# contrasts(sample_model_pred$dependence) <- c(-0.5, 0.5)
#
# colnames(attr(sample_model_pred$pert_direct, "contrasts")) <-
#   c("Perturb down - Perturb up")
#
# colnames(attr(sample_model_pred$dependence, "contrasts")) <-
#   c("Compatible - Incompatible")
sample_model <- mixed(jump_upper~pert_direct*dependence*preview + (1|id) + (1|reward), data=sample_model_pred,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
sample_model
plot_grid(
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "id") + theme_apa(),
afex_plot(sample_model, x = "preview", trace = "dependence",
panel = "pert_direct", id = "reward") + theme_apa(),
labels = c("ID", "Item")
)
# 54 participants, 6 repetitions in each cell
set.seed(1234)
reward.random.df <- data_frame(
reward = rep(c(10, 20, 30, 40, 50, 60, 70, 80, 90), times = 3888),
pert_direct = rep(c(rep(0, times = 9), rep(1, times = 9)), times = 1944),
dependence = rep(c(rep(1, times = 18), rep(2, times = 18)), times = 972),
preview = rep(c(rep("short", times = 216), rep("medium", times = 216), rep("long", times = 216)), times = 50),
id = rep(1:54, each = 648),
jump_upper = rbernoulli(34992, p = 0.5)
)
# kick out about 10 percent of rows - anticipated mean error rate
reward.random.df <- reward.random.df[-sample(1:34992, round(34992/10)),]
reward.random.df$reward <- factor(reward.random.df$reward)
reward.random.df$id <- factor(reward.random.df$id)
reward.random.df$pert_direct <- factor(reward.random.df$pert_direct, levels = c(0, 1))
contrasts(reward.random.df$pert_direct) <- c(-0.5, 0.5)
reward.random.df$dependence <- factor(reward.random.df$dependence, levels = c(1, 2))
contrasts(reward.random.df$dependence) <- c(-0.5, 0.5)
reward.random.df$preview <- factor(reward.random.df$preview, levels = c("short", "medium", "long"))
contrasts(reward.random.df$preview) <- contr.poly(3)
colnames(attr(reward.random.df$pert_direct, "contrasts")) <-
c("Perturb down - Perturb up")
colnames(attr(reward.random.df$dependence, "contrasts")) <-
c("Compatible - Incompatible")
colnames(attr(reward.random.df$preview, "contrasts")) <-
c("Linear trend", "Quadratic trend")
# make clusters for multithreading
(nc <- detectCores())
cl <- makeCluster(rep("localhost", nc))
null_model <- mixed(jump_upper ~ pert_direct*dependence*preview + (1|id) + (1|reward), data=reward.random.df,
family = binomial(link="logit"),
check_contrasts = F,
expand_re = T,
method = "LRT", args_test = list(cl =
cl), #nsim=1000
control = glmerControl(optimizer = "bobyqa",
optCtrl=list(maxfun=200000)), cl = cl)
summary(null_model)
fixed_coefs <- fixef(null_model$full_model)
fixed_coefs_length <- length(fixef(null_model$full_model))
coef_name_vector <- rep("COEF", fixed_coefs_length)
for (idx in (1:fixed_coefs_length)){
coef_name_vector[idx] <- names(fixed_coefs[idx])
}
coef_name_vector
sample_model <- null_model
# using estimates from first experiment with reward as random; based on this model:
# m_final_uncor_no3way_outliersRemoved_rewardRandom <- mixed(jump_upwards ~ dependence
#                                                            * pert_direct +
#                                                              (1 + dependence * pert_direct || id) + (1 + dependence + pert_direct || reward_upper),
#                                                            data = prop_up_jump_restricted_outliers_removed,
#                                                            family = binomial(link="logit"),
#                                                            check_contrasts = F,
#                                                            expand_re = T,
#                                                            method = "LRT", args_test = list(cl =
#                                                                                               cl), #nsim=1000
#                                                            control = glmerControl(optimizer = "bobyqa",
#                                                                                   optCtrl=list(maxfun=200000)), cl = cl)
fixef(sample_model$full_model)['(Intercept)'] <- 1.04975
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up'] <- -1.02224
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible'] <- 0.52140
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:previewLinear trend'] <- 0.6
fixef(sample_model$full_model)['pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend'] <- -0.4
VarCorr(sample_model$full_model)['id'] <- 2.426
VarCorr(sample_model$full_model)['reward'] <- 5.817
# SOURCE: osorensen, https://github.com/pitakakariki/simr/issues/39
# simulating for perturbation by preview interaction
# number of simulations 100
nsim <- 400L
# Function for repeatedly calling powerSim with nsim = 1
ps_function <- function(...) powerSim(..., nsim=1)
plan(multiprocess)
system.time(sim_pert_dep_preview <- future_replicate(nsim, ps_function(fit = sample_model$full_model, progress = FALSE,
test = fixed('pert_directPerturb down - Perturb up:dependenceCompatible - Incompatible:previewLinear trend')),
simplify = F))
# set significance threshold
alpha <- 0.05
# extract pvalues
pvals <- map_dbl(sim_pert_dep_preview, ~.x$pval)
# get the confidence interval
tibble(
successes = sum(pvals < alpha),
trials = length(pvals),
mean = successes / trials
) %>%
bind_cols(as_tibble(matrix(binconf(sum(.$successes), n = length(pvals), method = "exact")[, c("Lower", "Upper")],
nrow = 1, dimnames = list(NULL, c("Lower", "upper")))))
